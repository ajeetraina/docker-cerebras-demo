services:

  agents:
    image: demo/agents
    build:
      context: agent
    ports:
      - "7777:7777"
    environment:
      - OPENAI_API_KEY=$OPENAI_API_KEY
      # point agents at the MCP gateway
      - MCPGATEWAY_ENDPOINT=http://mcp-gateway:8811/sse
    volumes:
      # mount the agents file
      - ./agents.yaml:/agents.yaml
    depends_on:
      # model_runner provider starts first then injects environment variables
      # MODEL_RUNNER_MODEL name
      # MODEL_RUNNER_URL OpenAI compatible API endpoint
      - model_runner

  agents-ui:
    image: demo/ui
    build:
      context: agent-ui
    ports:
      - "3000:3000"
    environment:
      - AGENTS_URL=http://localhost:7777
    depends_on:
      - agents

  model_runner:
    provider:
      type: model
      options:
        # pre-pull the model when starting Docker Model Runner
        model: ai/qwen3:30B-A3B-Q4_K_M
        # increase context size to handle more github issues
        context-size: 41000

  mcp-gateway:
    # agents_gateway secures your MCP servers
    image: docker/mcp-gateway:latest
    command:
      # securely embed secrets into the gateway
      - --secrets=/run/secrets/mcp_secret
      # add any MCP servers you want to use
      - --servers=github-official
    volumes:
      # mount docker socket to run MCP containers
      - /var/run/docker.sock:/var/run/docker.sock
    secrets:
      - mcp_secret

# mount the secrets file for MCP servers
secrets:
  mcp_secret:
    file: ./.mcp.env
